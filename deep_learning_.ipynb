{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varunkumarjay/Deep-learning-lab-/blob/main/deep_learning_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "single perceptron, binary classification for iris dataset, for only one flower (flower choosen setosa)"
      ],
      "metadata": {
        "id": "u9vm7aQvC3_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data[:, :2]  # Use only the first two features (sepal length and sepal width)\n",
        "y = (iris.target == 0).astype(np.int32)  # Binary target: 1 for Setosa, 0 for Not Setosa\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, learning_rate=0.01, epochs=100):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def activation(self, z):\n",
        "        \"\"\"Step activation function.\"\"\"\n",
        "        return np.heaviside(z, 0).astype(int)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Train the perceptron using the dataset.\"\"\"\n",
        "        n_features = X.shape[1]\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        for _ in range(self.epochs):\n",
        "            for i in range(len(X)):\n",
        "                z = np.dot(X[i], self.weights) + self.bias\n",
        "                y_pred = self.activation(z)\n",
        "                update = self.learning_rate * (y[i] - y_pred)\n",
        "                self.weights += update * X[i]\n",
        "                self.bias += update\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Predict outputs for the given inputs.\"\"\"\n",
        "        z = np.dot(X, self.weights) + self.bias\n",
        "        return self.activation(z)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
        "\n",
        "# Initialize and train the perceptron\n",
        "perceptron = Perceptron(learning_rate=0.01, epochs=100)\n",
        "perceptron.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = perceptron.predict(X_test)\n",
        "\n",
        "# Evaluate the perceptron\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=[\"Not Setosa\", \"Setosa\"]))\n"
      ],
      "metadata": {
        "id": "0kSY_dxBCCSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "single layer perceptron using iris dataset\n"
      ],
      "metadata": {
        "id": "z3MKyZLhB5aX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBqkqi_OuSkf",
        "outputId": "e42b31c5-72e6-4099-e570-347c7ea04cb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Binary Classification for Setosa vs Not Setosa ---\n",
            "Accuracy: 0.96\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Not Setosa       1.00      0.93      0.97        46\n",
            "      Setosa       0.91      1.00      0.95        29\n",
            "\n",
            "    accuracy                           0.96        75\n",
            "   macro avg       0.95      0.97      0.96        75\n",
            "weighted avg       0.96      0.96      0.96        75\n",
            "\n",
            "\n",
            "--- Binary Classification for Versicolor vs Not Versicolor ---\n",
            "Accuracy: 0.71\n",
            "Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Not Versicolor       0.76      0.85      0.80        52\n",
            "    Versicolor       0.53      0.39      0.45        23\n",
            "\n",
            "      accuracy                           0.71        75\n",
            "     macro avg       0.64      0.62      0.62        75\n",
            "  weighted avg       0.69      0.71      0.69        75\n",
            "\n",
            "\n",
            "--- Binary Classification for Virginica vs Not Virginica ---\n",
            "Accuracy: 0.69\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "Not Virginica       1.00      0.56      0.72        52\n",
            "    Virginica       0.50      1.00      0.67        23\n",
            "\n",
            "     accuracy                           0.69        75\n",
            "    macro avg       0.75      0.78      0.69        75\n",
            " weighted avg       0.85      0.69      0.70        75\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data[:, :2]  # Use the first two features (sepal length and sepal width)\n",
        "\n",
        "def prepare_target(target_class):\n",
        "    \"\"\"Prepare binary target for the given class.\"\"\"\n",
        "    return (iris.target == target_class).astype(np.int32)\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, learning_rate=0.01, epochs=100):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def activation(self, z):\n",
        "        return np.heaviside(z, 0)  # Step activation function\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_features = X.shape[1]\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        for _ in range(self.epochs):\n",
        "            for i in range(len(X)):\n",
        "                z = np.dot(X[i], self.weights) + self.bias\n",
        "                y_pred = self.activation(z)\n",
        "                self.weights += self.learning_rate * (y[i] - y_pred) * X[i]\n",
        "                self.bias += self.learning_rate * (y[i] - y_pred)\n",
        "\n",
        "    def predict(self, X):\n",
        "        z = np.dot(X, self.weights) + self.bias\n",
        "        return self.activation(z)\n",
        "\n",
        "# Define the target classes\n",
        "classes = [\"Setosa\", \"Versicolor\", \"Virginica\"]\n",
        "\n",
        "# Loop through each class and train a perceptron\n",
        "for class_idx, class_name in enumerate(classes):\n",
        "    print(f\"\\n--- Binary Classification for {class_name} vs Not {class_name} ---\")\n",
        "\n",
        "    # Prepare binary targets\n",
        "    y = prepare_target(class_idx)\n",
        "\n",
        "    # Split the dataset\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
        "\n",
        "    # Initialize and train the perceptron\n",
        "    perceptron = Perceptron(learning_rate=0.01, epochs=100)\n",
        "    perceptron.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = perceptron.predict(X_test)\n",
        "\n",
        "    # Evaluate the perceptron\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy: {accuracy:.2f}\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=[f\"Not {class_name}\", class_name]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "multi class classification for vehicle dataset using single layer perceptron\n"
      ],
      "metadata": {
        "id": "v_D9SbzUBfmh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "Vr_28kONv3g8",
        "outputId": "a9172261-d351-4fdf-fc82-10439381bd0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:  1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Bike       1.00      1.00      1.00        10\n",
            "         Car       1.00      1.00      1.00        10\n",
            "       Truck       1.00      1.00      1.00        10\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Enter the attributes of the vehicle:\n",
            "\n",
            "The predicted vehicle type is: Bike\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/content/vehicle_dataset.csv\")\n",
        "\n",
        "# Preprocess the data (exclude \"Has Engine\" since all vehicles have engines)\n",
        "X = df[[\"Wheels\", \"Weight\"]].values\n",
        "y = df[\"Vehicle Type\"].values  # Car=0, Bike=1, Truck=2\n",
        "\n",
        "# Encode the target labels to integers\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)  # Converts 'Car', 'Bike', 'Truck' to 0, 1, 2\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Fix the train-test split for consistency\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "class MultiClassPerceptron:\n",
        "    def __init__(self, learning_rate, epochs, n_classes):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.n_classes = n_classes\n",
        "        self.weights = None\n",
        "        self.biases = None\n",
        "\n",
        "    def activation(self, z):\n",
        "        \"\"\"Identity activation for raw scores\"\"\"\n",
        "        return z\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_features = X.shape[1]\n",
        "        self.weights = np.zeros((self.n_classes, n_features))\n",
        "        self.biases = np.zeros(self.n_classes)\n",
        "\n",
        "        # Train one perceptron for each class (one-vs-all)\n",
        "        for epoch in range(self.epochs):\n",
        "            for i in range(len(X)):\n",
        "                for c in range(self.n_classes):\n",
        "                    # Binary target for class c\n",
        "                    target = 1 if y[i] == c else 0\n",
        "\n",
        "                    # Compute the output for class c\n",
        "                    z = np.dot(X[i], self.weights[c]) + self.biases[c]\n",
        "                    y_pred = self.activation(z) >= 0  # Heaviside function\n",
        "\n",
        "                    # Update weights and biases for class c\n",
        "                    self.weights[c] += self.learning_rate * (target - y_pred) * X[i]\n",
        "                    self.biases[c] += self.learning_rate * (target - y_pred)\n",
        "\n",
        "    def predict(self, X):\n",
        "        scores = np.dot(X, self.weights.T) + self.biases\n",
        "        return np.argmax(scores, axis=1)\n",
        "\n",
        "# Initialize and train the perceptron\n",
        "perceptron = MultiClassPerceptron(learning_rate=0.01, epochs=200, n_classes=3)\n",
        "perceptron.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = perceptron.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "# Visualize the dataset (optional)\n",
        "def visualize_data(X, y):\n",
        "    plt.scatter(X[:, 0][y == 0], X[:, 1][y == 0], label=\"Car\", c=\"red\", edgecolor=\"k\")\n",
        "    plt.scatter(X[:, 0][y == 1], X[:, 1][y == 1], label=\"Bike\", c=\"blue\", edgecolor=\"k\")\n",
        "    plt.scatter(X[:, 0][y == 2], X[:, 1][y == 2], label=\"Truck\", c=\"green\", edgecolor=\"k\")\n",
        "    plt.xlabel(\"Wheels (normalized)\")\n",
        "    plt.ylabel(\"Weight (normalized)\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Vehicle Data Visualization\")\n",
        "    plt.show()\n",
        "\n",
        "visualize_data(X, y)\n",
        "\n",
        "# Function to predict a vehicle type based on user input\n",
        "def predict_vehicle():\n",
        "    print(\"\\nEnter the attributes of the vehicle:\")\n",
        "    wheels = int(input(\"Number of wheels: \"))\n",
        "    weight = float(input(\"Weight: \"))\n",
        "\n",
        "    # Create the input feature array\n",
        "    input_features = np.array([[wheels, weight]])\n",
        "\n",
        "    # Normalize the input features\n",
        "    input_features = scaler.transform(input_features)\n",
        "\n",
        "    # Predict the vehicle type\n",
        "    prediction = perceptron.predict(input_features)\n",
        "    vehicle_type = label_encoder.inverse_transform(prediction)\n",
        "\n",
        "    print(f\"\\nThe predicted vehicle type is: {vehicle_type[0]}\")\n",
        "\n",
        "# Call the function to predict a vehicle\n",
        "predict_vehicle()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "single layer perceptron for AND operator"
      ],
      "metadata": {
        "id": "OyvaMFTKBTeN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def step_function(x):\n",
        "    return np.where(x > 0, 1, 0)  # Apply step function to an array\n",
        "\n",
        "class SingleLayerPerceptron:\n",
        "    def __init__(self, input_size, output_size, learning_rate=0.1):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weights = np.random.rand(output_size, input_size)\n",
        "        self.biases = np.random.rand(output_size)\n",
        "\n",
        "    def predict(self, inputs):\n",
        "        linear_output = np.dot(inputs, self.weights.T) + self.biases\n",
        "        return step_function(linear_output)\n",
        "\n",
        "    def train(self, inputs, labels, epochs=1000):\n",
        "        for _ in range(epochs):\n",
        "            for input_vector, label_vector in zip(inputs, labels):\n",
        "                prediction = self.predict(input_vector)\n",
        "                error = label_vector - prediction\n",
        "                self.weights += self.learning_rate * np.outer(error, input_vector)\n",
        "                self.biases += self.learning_rate * error\n",
        "\n",
        "# Inputs and labels for AND gate\n",
        "inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "labels = np.array([[0], [0], [0], [1]])  # AND gate output\n",
        "\n",
        "# Train perceptron\n",
        "and_perceptron = SingleLayerPerceptron(input_size=2, output_size=1)\n",
        "and_perceptron.train(inputs, labels, epochs=1000)\n",
        "\n",
        "print(\"AND Gate Predictions:\")\n",
        "for input_vector in inputs:\n",
        "    print(f\"{input_vector} -> {and_perceptron.predict(input_vector)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekbkhPsylArC",
        "outputId": "d69c2c7f-81e7-4a77-fcda-a08425a66b21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AND Gate Predictions:\n",
            "[0 0] -> [0]\n",
            "[0 1] -> [0]\n",
            "[1 0] -> [0]\n",
            "[1 1] -> [1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "single layer perceptron for OR operator"
      ],
      "metadata": {
        "id": "E47HH2iBBJd2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def step_function(x):\n",
        "    return np.where(x > 0, 1, 0)  # Apply step function to an array\n",
        "\n",
        "class SingleLayerPerceptron:\n",
        "    def __init__(self, input_size, output_size, learning_rate=0.1):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weights = np.random.rand(output_size, input_size)\n",
        "        self.biases = np.random.rand(output_size)\n",
        "\n",
        "    def predict(self, inputs):\n",
        "        linear_output = np.dot(inputs, self.weights.T) + self.biases\n",
        "        return step_function(linear_output)\n",
        "\n",
        "    def train(self, inputs, labels, epochs=1000):\n",
        "        for _ in range(epochs):\n",
        "            for input_vector, label_vector in zip(inputs, labels):\n",
        "                prediction = self.predict(input_vector)\n",
        "                error = label_vector - prediction\n",
        "                self.weights += self.learning_rate * np.outer(error, input_vector)\n",
        "                self.biases += self.learning_rate * error\n",
        "\n",
        "# Inputs and labels for OR gate\n",
        "inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "labels = np.array([[0], [1], [1], [1]])  # OR gate output\n",
        "\n",
        "# Train perceptron\n",
        "or_perceptron = SingleLayerPerceptron(input_size=2, output_size=1)\n",
        "or_perceptron.train(inputs, labels, epochs=1000)\n",
        "\n",
        "print(\"OR Gate Predictions:\")\n",
        "for input_vector in inputs:\n",
        "    print(f\"{input_vector} -> {or_perceptron.predict(input_vector)}\")\n"
      ],
      "metadata": {
        "id": "2HCTThtxmdLL",
        "outputId": "f0d305a8-0e48-4c3d-975c-e2c340690475",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OR Gate Predictions:\n",
            "[0 0] -> [0]\n",
            "[0 1] -> [1]\n",
            "[1 0] -> [1]\n",
            "[1 1] -> [1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment-3\n",
        "multilayer perceptron for xor dataset"
      ],
      "metadata": {
        "id": "-GlWs9ZN71DU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.initializers import HeNormal\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# XOR Dataset\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "Y = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "# Model Definition\n",
        "model = Sequential([\n",
        "    Dense(8, input_dim=2, activation='relu', kernel_initializer=HeNormal()),  # Hidden layer 1\n",
        "    Dense(4, activation='relu', kernel_initializer=HeNormal()),              # Hidden layer 2\n",
        "    Dense(1, activation='sigmoid')                                           # Output layer\n",
        "])\n",
        "\n",
        "# Compile Model\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)  # Increased learning rate\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Early Stopping\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=50, restore_best_weights=True)\n",
        "\n",
        "# Train Model\n",
        "model.fit(X, Y, epochs=1000, batch_size=2, verbose=0, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate Model\n",
        "loss, accuracy = model.evaluate(X, Y, verbose=0)\n",
        "print(f\"Model Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Test Predictions\n",
        "predictions = model.predict(X)\n",
        "print(\"Predictions:\")\n",
        "for inp, pred in zip(X, predictions):\n",
        "    print(f\"Input: {inp}, Predicted Output: {np.round(pred[0], 2)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Joekmg0C70mN",
        "outputId": "a1444f7a-adb6-4af8-a858-000efbe0f2dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Loss: 0.0001, Accuracy: 1.0000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
            "Predictions:\n",
            "Input: [0 0], Predicted Output: 0.0\n",
            "Input: [0 1], Predicted Output: 1.0\n",
            "Input: [1 0], Predicted Output: 1.0\n",
            "Input: [1 1], Predicted Output: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "experiment 4 activation function (comparing activation functions)"
      ],
      "metadata": {
        "id": "vLQZmxsvDa3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.initializers import HeNormal\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# XOR Dataset (Non-linearly separable)\n",
        "X_XOR = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "Y_XOR = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "# AND Dataset (Linearly separable)\n",
        "X_AND = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "Y_AND = np.array([[0], [0], [0], [1]])\n",
        "\n",
        "# Function to create and train a model with a given activation function\n",
        "def build_and_train_model(X, Y, activation, dataset_name):\n",
        "    print(f\"\\nTraining with {activation} activation on {dataset_name} dataset\")\n",
        "\n",
        "    # Define the model\n",
        "    model = Sequential([\n",
        "        Input(shape=(2,)),\n",
        "        Dense(8, activation=activation, kernel_initializer=HeNormal()),\n",
        "        Dense(4, activation=activation, kernel_initializer=HeNormal()),\n",
        "        Dense(1, activation='sigmoid')  # Output layer uses sigmoid for binary classification\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=Adam(learning_rate=0.01), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X, Y, epochs=500, batch_size=2, verbose=0)\n",
        "\n",
        "    # Evaluate the model\n",
        "    loss, accuracy = model.evaluate(X, Y, verbose=0)\n",
        "    print(f\"Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model.predict(X, verbose=0)\n",
        "    predictions_binary = (predictions > 0.5).astype(int)\n",
        "\n",
        "    # Print predictions and classification report\n",
        "    print(\"Predictions:\")\n",
        "    for inp, pred, binary in zip(X, predictions, predictions_binary):\n",
        "        print(f\"Input: {inp}, Output: {pred[0]:.4f}, Binary Output: {binary[0]}\")\n",
        "\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(Y, predictions_binary, target_names=[\"Class 0\", \"Class 1\"]))\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Compare activation functions on both datasets\n",
        "datasets = [(\"XOR\", X_XOR, Y_XOR), (\"AND\", X_AND, Y_AND)]\n",
        "activations = ['sigmoid', 'relu', 'tanh']\n",
        "\n",
        "for dataset_name, X, Y in datasets:\n",
        "    print(f\"\\n--- {dataset_name} Dataset ---\")\n",
        "    for activation in activations:\n",
        "        build_and_train_model(X, Y, activation, dataset_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hgkCdkBD9uy",
        "outputId": "cb6048c4-430b-4732-82e3-1f398aa69950"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- XOR Dataset ---\n",
            "\n",
            "Training with sigmoid activation on XOR dataset\n",
            "Loss: 0.0646, Accuracy: 1.0000\n",
            "Predictions:\n",
            "Input: [0 0], Output: 0.0836, Binary Output: 0\n",
            "Input: [0 1], Output: 0.9259, Binary Output: 1\n",
            "Input: [1 0], Output: 0.9940, Binary Output: 1\n",
            "Input: [1 1], Output: 0.0844, Binary Output: 0\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       1.00      1.00      1.00         2\n",
            "     Class 1       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         4\n",
            "   macro avg       1.00      1.00      1.00         4\n",
            "weighted avg       1.00      1.00      1.00         4\n",
            "\n",
            "\n",
            "Training with relu activation on XOR dataset\n",
            "Loss: 0.0161, Accuracy: 1.0000\n",
            "Predictions:\n",
            "Input: [0 0], Output: 0.0311, Binary Output: 0\n",
            "Input: [0 1], Output: 0.9995, Binary Output: 1\n",
            "Input: [1 0], Output: 0.9995, Binary Output: 1\n",
            "Input: [1 1], Output: 0.0311, Binary Output: 0\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       1.00      1.00      1.00         2\n",
            "     Class 1       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         4\n",
            "   macro avg       1.00      1.00      1.00         4\n",
            "weighted avg       1.00      1.00      1.00         4\n",
            "\n",
            "\n",
            "Training with tanh activation on XOR dataset\n",
            "Loss: 0.0018, Accuracy: 1.0000\n",
            "Predictions:\n",
            "Input: [0 0], Output: 0.0010, Binary Output: 0\n",
            "Input: [0 1], Output: 0.9967, Binary Output: 1\n",
            "Input: [1 0], Output: 0.9989, Binary Output: 1\n",
            "Input: [1 1], Output: 0.0018, Binary Output: 0\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       1.00      1.00      1.00         2\n",
            "     Class 1       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         4\n",
            "   macro avg       1.00      1.00      1.00         4\n",
            "weighted avg       1.00      1.00      1.00         4\n",
            "\n",
            "\n",
            "--- AND Dataset ---\n",
            "\n",
            "Training with sigmoid activation on AND dataset\n",
            "Loss: 0.0116, Accuracy: 1.0000\n",
            "Predictions:\n",
            "Input: [0 0], Output: 0.0044, Binary Output: 0\n",
            "Input: [0 1], Output: 0.0071, Binary Output: 0\n",
            "Input: [1 0], Output: 0.0071, Binary Output: 0\n",
            "Input: [1 1], Output: 0.9726, Binary Output: 1\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       1.00      1.00      1.00         3\n",
            "     Class 1       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         4\n",
            "   macro avg       1.00      1.00      1.00         4\n",
            "weighted avg       1.00      1.00      1.00         4\n",
            "\n",
            "\n",
            "Training with relu activation on AND dataset\n",
            "Loss: 0.0155, Accuracy: 1.0000\n",
            "Predictions:\n",
            "Input: [0 0], Output: 0.0001, Binary Output: 0\n",
            "Input: [0 1], Output: 0.0003, Binary Output: 0\n",
            "Input: [1 0], Output: 0.0003, Binary Output: 0\n",
            "Input: [1 1], Output: 0.9404, Binary Output: 1\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       1.00      1.00      1.00         3\n",
            "     Class 1       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         4\n",
            "   macro avg       1.00      1.00      1.00         4\n",
            "weighted avg       1.00      1.00      1.00         4\n",
            "\n",
            "\n",
            "Training with tanh activation on AND dataset\n",
            "Loss: 0.0013, Accuracy: 1.0000\n",
            "Predictions:\n",
            "Input: [0 0], Output: 0.0005, Binary Output: 0\n",
            "Input: [0 1], Output: 0.0011, Binary Output: 0\n",
            "Input: [1 0], Output: 0.0010, Binary Output: 0\n",
            "Input: [1 1], Output: 0.9973, Binary Output: 1\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       1.00      1.00      1.00         3\n",
            "     Class 1       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         4\n",
            "   macro avg       1.00      1.00      1.00         4\n",
            "weighted avg       1.00      1.00      1.00         4\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "experiment 5\n"
      ],
      "metadata": {
        "id": "hJelhg3j0wtO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sigmoid activation function and its derivative\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def sigmoid_derivative(z):\n",
        "    return sigmoid(z) * (1 - sigmoid(z))\n",
        "\n",
        "# Initialize parameters for a 2-layer neural network\n",
        "def initialize_parameters(input_size, hidden_size, output_size):\n",
        "    np.random.seed(42)  # For reproducibility\n",
        "    W1 = np.random.randn(hidden_size, input_size) * 0.01\n",
        "    b1 = np.zeros((hidden_size, 1))\n",
        "    W2 = np.random.randn(output_size, hidden_size) * 0.01\n",
        "    b2 = np.zeros((output_size, 1))\n",
        "    return W1, b1, W2, b2\n",
        "\n",
        "# Forward propagation\n",
        "def forward_propagation(X, W1, b1, W2, b2):\n",
        "    Z1 = np.dot(W1, X) + b1\n",
        "    A1 = sigmoid(Z1)\n",
        "    Z2 = np.dot(W2, A1) + b2\n",
        "    A2 = sigmoid(Z2)\n",
        "    cache = (Z1, A1, Z2, A2)\n",
        "    return A2, cache\n",
        "\n",
        "# Compute cost\n",
        "def compute_cost(A2, Y):\n",
        "    m = Y.shape[1]\n",
        "    cost = -np.sum(Y * np.log(A2) + (1 - Y) * np.log(1 - A2)) / m\n",
        "    return np.squeeze(cost)\n",
        "\n",
        "# Backward propagation\n",
        "def backward_propagation(X, Y, cache, W1, W2):\n",
        "    m = X.shape[1]\n",
        "    Z1, A1, Z2, A2 = cache\n",
        "\n",
        "    dZ2 = A2 - Y\n",
        "    dW2 = np.dot(dZ2, A1.T) / m\n",
        "    db2 = np.sum(dZ2, axis=1, keepdims=True) / m\n",
        "\n",
        "    dZ1 = np.dot(W2.T, dZ2) * sigmoid_derivative(Z1)\n",
        "    dW1 = np.dot(dZ1, X.T) / m\n",
        "    db1 = np.sum(dZ1, axis=1, keepdims=True) / m\n",
        "\n",
        "    return dW1, db1, dW2, db2\n",
        "\n",
        "# Update parameters\n",
        "def update_parameters(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate):\n",
        "    W1 -= learning_rate * dW1\n",
        "    b1 -= learning_rate * db1\n",
        "    W2 -= learning_rate * dW2\n",
        "    b2 -= learning_rate * db2\n",
        "    return W1, b1, W2, b2\n",
        "\n",
        "# XOR dataset\n",
        "X = np.array([[0, 0, 1, 1], [0, 1, 0, 1]])  # Input features\n",
        "Y = np.array([[0, 1, 1, 0]])  # Labels\n",
        "\n",
        "# Neural network parameters\n",
        "input_size = 2\n",
        "hidden_size = 4\n",
        "output_size = 1\n",
        "learning_rate = 0.1\n",
        "epochs = 10000\n",
        "\n",
        "# Initialize parameters\n",
        "W1, b1, W2, b2 = initialize_parameters(input_size, hidden_size, output_size)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    # Forward propagation\n",
        "    A2, cache = forward_propagation(X, W1, b1, W2, b2)\n",
        "\n",
        "    # Compute cost\n",
        "    cost = compute_cost(A2, Y)\n",
        "\n",
        "    # Backward propagation\n",
        "    dW1, db1, dW2, db2 = backward_propagation(X, Y, cache, W1, W2)\n",
        "\n",
        "    # Update parameters\n",
        "    W1, b1, W2, b2 = update_parameters(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate)\n",
        "\n",
        "    # Print cost every 1000 iterations\n",
        "    if epoch % 1000 == 0:\n",
        "        print(f\"Epoch {epoch}, Cost: {cost:.4f}\")\n",
        "\n",
        "# Final predictions\n",
        "A2, _ = forward_propagation(X, W1, b1, W2, b2)\n",
        "predictions = (A2 > 0.5).astype(int)\n",
        "print(\"\\nPredictions:\")\n",
        "print(predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnzTCu7V0yzu",
        "outputId": "4f243585-e2b4-466b-c8c3-02ead7e934f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Cost: 0.6931\n",
            "Epoch 1000, Cost: 0.6931\n",
            "Epoch 2000, Cost: 0.6931\n",
            "Epoch 3000, Cost: 0.6931\n",
            "Epoch 4000, Cost: 0.6931\n",
            "Epoch 5000, Cost: 0.6931\n",
            "Epoch 6000, Cost: 0.6931\n",
            "Epoch 7000, Cost: 0.6931\n",
            "Epoch 8000, Cost: 0.6931\n",
            "Epoch 9000, Cost: 0.6931\n",
            "\n",
            "Predictions:\n",
            "[[0 1 0 1]]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/ORNLkxbdMbUd0FV6Bj/E",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}